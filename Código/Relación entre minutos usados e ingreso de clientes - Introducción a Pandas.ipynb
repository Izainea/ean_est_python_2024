{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Existe relación alguna entre el total de minutos usados con la compañía y el ingreso total de los clientes?\n",
    "En el desarrollo de este caso introduciremos las librerías pandas, numpy y matplotlib para el preprocesamiento, visualización de un conjunto de datos y el desarrollo de algunas medidas estadísticas descriptivas.\n",
    "\n",
    "\n",
    "\n",
    "##  Introducción \n",
    "\n",
    "La revisión del comportamiento de los clientes en cualquier empresa es de vital importancia para el desarrollo de estrategias  tanto de mejoramiento de productos como de publicidad y toma de decisiones. Evaluaremos la información obtenida de un conjunto de registro obtenidos de una empresa de telecomunicaciones que cuenta con la revisión de las siguientes variables:\n",
    "\n",
    "1. totrev: Ingresos del cliente\n",
    "2. totmou: Total de minutos usados por el cliente\n",
    "3. area: Área geográfica\n",
    "4. creditcd: Indicador de tarjeta de crédito\n",
    "5. eqpdays: Número de días (antigüedad) del equipo actual\n",
    "\n",
    "Es importante mencionar que la empresa contiene una gran cantidad de clientes y hacer el análisis uno a uno no es lo  óptimo. Con ayuda de la programación y el análisis de datos, se logrará llegar a conclusiones rápidas y acertadas para encontrar relaciones que a simple vista no son tenidas en cuenta.\n",
    "\n",
    "### ¿Qué se quiere identificar? \n",
    "\n",
    "Teniendo en cuenta la información de la base de datos se quiere identificar si hay una relación entre el total de minutos usados por el cliente con la compañía y el ingreso total de los clientes, es decir, Será posible afirmar que cuando una persona\n",
    "tiene un mayor ingreso mayor entonces es mayor la utilización de minutos o todo lo contrario?\n",
    "\n",
    "\n",
    "####  Insumos para tratar este problema\n",
    "\n",
    "\n",
    "Teniendo en cuenta que la compañía tenia estándares para la entrega de la información, se dispone de un  conjunto de tablas en formato CSV ordenado de la siguiente manera:\n",
    "La información de este conjunto de datos puede encontrase en [aquí](https://www.kaggle.com/abhinav89/telecom-customer?select=Telecom_customer+churn.csv)\n",
    "\n",
    "### Objetivos\n",
    "\n",
    "En este caso usted tendrá que cargar varias bases de datos, hará una exploración básica sobre la información y fusionará las distintas bases para tener una visión general del problema. La idea es que desarrolle las siguientes habilidades:\n",
    "\n",
    "1. Manejo de la librería pandas de Python para cargar y leer datos; \n",
    "2. Ideas elementales para una útil transformación de los datos;\n",
    "3. Construcción y presentación de argumentos válidos que le brindarán una solución para la pregunta expresada más arriba y llegar a una conclusión. \n",
    "4. Visualización de gráficas elementales que le permitirá entender mejor la información contenida en los datos.\n",
    "\n",
    "#### Importación de paquetes\n",
    "\n",
    "\n",
    "Una de las mejores opciones para trabajar con datos tabulares en Python es usar el módulo pandas. La librería `pandas` provee estructuras de datos, genera gráficos de alta calidad con `matplotlib` y se integra de buena forma con otras librerías que usan arrays de `numpy`.\n",
    "\n",
    "Debemos revisar si la librería se encuentra en nuestro sistema usando el comando \n",
    "\n",
    "```python\n",
    "!pip show librería\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip show pandas\n",
    "#!pip show numpy\n",
    "#!pip show matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de que la librería no se encuentre instalada ejecutamos el comando\n",
    "\n",
    "```python\n",
    "!pip install librería\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para importar las librerías usamos el comando \n",
    "```python\n",
    "import librería as alias\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de que tener los paquetes activados dentro de nuestro ambiente de python podremos usar las fucnciones que se encuentren en la librería."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción a pandas\n",
    "\n",
    "Poner información sobre pandas e indicar la diferencia entre series y dataframe\n",
    "\n",
    "![](https://www.cdn.geeksforgeeks.org/wp-content/uploads/creating_dataframe1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, mostramos el código a ejecutar para crear una ` Serie`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Serie1 = pd.Series(\n",
    "index=['Primero', 'Segundo', 'Tercero', 'Cuarto', 'Quinto'], name=\"Variable1\", data=[\"A\",\"B\",\"C\",\"D\",\"E\"]\n",
    ")\n",
    "Serie1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Frame = pd.DataFrame( \n",
    "index=['Primero', 'Segundo', 'Tercero', 'Cuarto', 'Quinto'],\n",
    "    columns=[\"Variable2\",\"Variable3\"], \n",
    "    data=[['Hola', 12], [2, 22],[3,32],[4,42],[5,52]]\n",
    ")\n",
    "Data_Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para revisar el tipo de objeto que contiene nuestro DataFrame podemos ejecutar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Frame.dtypes\n",
    "#Serie1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraer datos sobre la base:\n",
    "\n",
    "Si quiero conocer una columna de la base simplemente escribo `DataFrame['nombre_columna']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Frame[['Variable2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Frame['Variable1']=Serie1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quiero ver varias columnas de la base de datos, utilizo doble paréntesis cuadrado:\n",
    "\n",
    "`DataFrame[['columna1','columna2']]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Frame[['Variable1','Variable2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quiero ver datos por registros utilizo loc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Frame.loc[['Primero','Tercero','Quinto']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Frame.iloc[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de información en `pandas`\n",
    "\n",
    "Para nuestro  ejercicio usaremos los siguientes conjuntos de datos:\n",
    "\n",
    "1. NEW ENGLAND AREA.csv\n",
    "2. ATLANTIC SOUTH AREA.csv\n",
    "3. NEW YORK CITY AREA.csv\n",
    "4. CHICAGO AREA.csv\n",
    "5. NORTH FLORIDA AREA.csv\n",
    "6. DC-MARYLAND-VIRGINIA AREA.csv\n",
    "7. GREAT LAKES AREA.csv\n",
    "8. NORTHWEST-ROCKY MOUNTAIN AREA.csv\n",
    "9. MIDWEST AREA.csv\n",
    "10. SOUTHWEST AREA.csv\n",
    "11. LOS ANGELES AREA.csv\n",
    "12. HOUSTON AREA.csv\n",
    "13. CALIFORNIA NORTH AREA.csv\n",
    "14. CENTRAL-SOUTH TEXAS AREA.csv\n",
    "15. DALLAS AREA.csv\n",
    "16. PHILADELPHIA AREA.csv\n",
    "17. TENNESSEE AREA.csv\n",
    "18. OHIO AREA.csv\n",
    "19. SOUTH FLORIDA AREA.csv\n",
    "\n",
    "Cada uno de estos conjuntos de datos contiene la información de:\n",
    "\n",
    "1. *mou_Mean:* Número medio de minutos de uso mensuales\n",
    "2. *custcare_Mean:* Número medio de llamadas de atención al cliente\n",
    "3. *area:*  Área geografica\n",
    "4. *creditcd:* Indicador de tarjeta de crédito\n",
    "5. *eqpdays:* Número de días (antigüedad) del equipo actual\n",
    "\n",
    "Además, se incluye _Credito_dias.csv_ con la información de 2 variables adicionales para los registros las cuales son:\n",
    "\n",
    "1. _creditcd:_ Indicador de tarjeta de crédito\n",
    "2. _eqpdays:_ Número de días (antigüedad) del equipo actual\n",
    "\n",
    "Revisaremos inicialmente los datos contenidos en _Credito_dias.csv_ para revisar algunas funciones interesantes de `pandas`, usaremos el comando \n",
    "```python\n",
    "pd.read_csv(\"archivo.csv\")\n",
    "```\n",
    "Podemos definir el número de registros a imprimir usando\n",
    "```python\n",
    "pd.options.display.min_rows=10\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Bases/Credito_dias.csv\", sep=\",\",index_col=\"Customer_ID\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos se encuentra en el `DataFrame` `df`\n",
    "\n",
    "sobre el objeto creado podemos usar  algunas funciones  para darnos una idea del comportamiento de la información:\n",
    "```python\n",
    "df.head(n)  # imprime los primeros n registros del DataFrame\n",
    "df.tail(n)  # imprime los últimos n registros del DataFrame \n",
    "df.shape    # imprime el numero de columnas y filas del DataFrame\n",
    "df.columns  # imprime el nombre de las columnas del DataFrame\n",
    "df.index    # imprime el indice de los registros del DataFrame\n",
    "df.dtypes   # imprime el tipo de cada una de las columnnas del DataFrame\n",
    "df.sample(n)# imprime una muestra aleatoria de n registros en el DataFrame\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"primeros 3 registros\",df.head(3))\n",
    "display(\"3 últimos registros\",df.tail(3))\n",
    "display(\"Columnas:\",df.columns)\n",
    "display(\"Índices:\",df.index)\n",
    "display(\"Tipos de registros en el DataFrame\",df.dtypes)\n",
    "display(\"Muestra aleatoria de 3 registros\",df.sample(3))\n",
    "display(\"dimensión\",df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este conjunto de datos corresponde a 10000 registros y 2 variables\n",
    "\n",
    "### Manejo de datos duplicados \n",
    "\n",
    "os dataframes tienen la posibilidad de detectar las filas duplicadas con la función: \n",
    "```\n",
    "df.duplicated({columns})\n",
    "```\n",
    "Si no especifica {columns}, se busacarán duplicados teniendo en cuenta todas las columnas. Una vez detectados el dtaframe tiene un función para eliminar filas duplicadas, haciendo:\n",
    "\n",
    "```\n",
    "df = df.drop_duplicates()\n",
    "```\n",
    "También es posible eliminar filas que duplican solo algunos campos. Con el fin de dejar solo una ocurrencia.\n",
    "\n",
    "```\n",
    "df.drop_duplicates(['nombre', 'apellido', 'cédula'], keep='last')\n",
    "```\n",
    "En este caso, como no todas las colomnas son iguales se conserva solo la última ocurrencia.\n",
    "\n",
    "### Manejo de datos perdidos o esperados\n",
    "Son aquellos datos flatantes en la tabla que por alguna razón o error no se encuentran, o parecen con algún valor o etiqueta de no válido. \n",
    "Para manipular datos perdidos use la explicación dada el siguiente enlace: [DATOS PERDIDOS](http://ligdigonzalez.com/manipulando-datos-perdidos-en-python/)\n",
    "recuerde que para reemplazar datos perdidos en un dataframe $df$ se usa la función:\n",
    "```python\n",
    "promedio = df['totrev'].mean()\n",
    "df['nota'].replace(np.nan, promedio)\n",
    "```\n",
    "en donde la opción 'promedio' busca el valor promedio de la columna (datos numéricos) o la moda (datos categóricos) para reemplazar el valor no válido.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perd=df.isnull().any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[perd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perdidos = df[df.isnull().any(axis=1)]\n",
    "perdidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['totrev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "promedio = df['totrev'].mean()\n",
    "df['totrev']=df['totrev'].replace(np.nan, promedio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También es recomendado usar la funcion `fillna()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['creditcd'].fillna(\"Y\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[perd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Cálculo de estadísticas resumen\n",
    "\n",
    "Las medidas estadísticas resumen son de gran ayuda para comprender como es el comportamiento de la distribución de los datos, los objetos `DataFrame` ofrecen facilidades para hacer el cálculo de algunas estadísticas sobre cada una de las variables.\n",
    "\n",
    "```python\n",
    "df[\"var\"].value_counts() # Encuentra la frecuencia de las categorias de una columna (la columna debe ser cualitativa)\n",
    "df[\"var\"].min()          # Encuentra el mínimo de una variable cuantitativa\n",
    "df[\"var\"].median()       # Encuentra el mínimo de una variable cuantitativa\n",
    "df[\"var\"].mean()         # Encuentra el promedio de una variable cuantitativa\n",
    "df[\"var\"].max()          # Encuentra el máximo de una variable cuantitativa\n",
    "df[\"var\"].quantile()     # Encuentra los cuantiles de una variable cuantitativa\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"creditcd\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"creditcd\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"eqpdays\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"eqpdays\"]=[0 if i<0 else i for i in df[\"eqpdays\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"eqpdays\"].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La exploración del anterior resultado puede mostrar inconsistencias  en los registros y nos ayudará a tomar decisiones sobre algunos registros, el valor mínimo de la variable `eqpdays` (Número de días (antigüedad) del equipo actual) debería ser estrictamente positivo y estos pueden ser errores de ingreso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"eqpdays\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"eqpdays\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"eqpdays\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"eqpdays\"].quantile(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"eqpdays\"].quantile(0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas estadísticas pueden ser resumidas con el comando:\n",
    "```python\n",
    "df[\"var\"].describe()  # Estadísticas resumen principales\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"eqpdays\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['creditcd'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregar información de múltiples tablas\n",
    "\n",
    "Hemos desarrollado un breve resumen estadístico solamente usando la base `Credito_dias.csv`. Realizaremos la combinación de las 19 áreas que nos reportan en los archivos csv. Una forma de lograr esta tarea de agregación es usar el método pd.concat() de pandas. Una entrada en este método puede ser una lista de DataFrames que quiera concatenar. Usaremos un ciclo  `for` sobre cada uno de los archivos de áreas para \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1\n",
    "Determinar los percentiles 25, 50 y 75 para las columnas ttomou, totrev, eqpdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Espacio para el desarrollo del ejercicio\n",
    "df[\"totmou\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"totrev\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"Bases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Definición de los símbolos de las acciones\")\n",
    "areas = ['ATLANTIC SOUTH AREA',\n",
    " 'CALIFORNIA NORTH AREA',\n",
    " 'CENTRAL-SOUTH TEXAS AREA',\n",
    " 'CHICAGO AREA',\n",
    " 'DALLAS AREA',\n",
    " 'DC-MARYLAND-VIRGINIA AREA',\n",
    " 'GREAT LAKES AREA',\n",
    " 'HOUSTON AREA',\n",
    " 'LOS ANGELES AREA',\n",
    " 'MIDWEST AREA',\n",
    " 'NEW ENGLAND AREA',\n",
    " 'NEW YORK CITY AREA',\n",
    " 'NORTH FLORIDA AREA',\n",
    " 'NORTHWEST-ROCKY MOUNTAIN AREA',\n",
    " 'OHIO AREA',\n",
    " 'PHILADELPHIA AREA',\n",
    " 'SOUTH FLORIDA AREA',\n",
    " 'SOUTHWEST AREA',\n",
    " 'TENNESSEE AREA']\n",
    "lista_de_df = []\n",
    "# Bucle sobre los símbolos\n",
    "print(\" --- Inicie el bucle sobre los símbolos --- \")\n",
    "for i in areas:\n",
    "    print(\"Procesando el símbolo: \" + i)\n",
    "    temp_df = pd.read_csv(\"Bases/\" + i + \".csv\",index_col=\"Customer_ID\")\n",
    "    temp_df[\"area\"] = i\n",
    "    lista_de_df.append(temp_df)\n",
    "    # Usando un salto de línea al final de esta cadena de caracteres por estética\n",
    "    print(\" --- Bucle completo sobre los símbolos --- \\n\")\n",
    "    # Combinando en un solo DataFrame usando el concat\n",
    "print(\"Agregando los datos\")\n",
    "agr_df = pd.concat(lista_de_df, axis=0)\n",
    "print(agr_df.shape)\n",
    "print(\"Cabeza del DataFrame agr_df: \")\n",
    "agr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agr_df.sort_index(axis=0,inplace=True)\n",
    "agr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ejecución nos da como resultado una base de datos de 9997 registros correspondiente a la concatenación de todas las áreas. Se debe notar que nuestro conjunto de datos también es indexado por la columna `Customer_ID` y que la dimensión de los registros de está nueva base es menor a la de  `Creditos_dias.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Cruce de información\n",
    "\n",
    "El cruce de información es una operación esencial en el análisis de los datos. Usualmente, la posibilidad de realizar el cruce de dos o más fuentes de información es el primer paso para responder preguntas complejas acerca de los datos. Existen muchas formas de cruzar o combinar tablas de datos. El cruce de estos datos siempre tiene un propósito. Por tanto, se debe realizar un análisis de lo que se requiere antes de iniciar. Para esto, lo primero es conocer bien las fuentes de información que se van a relacionar. \n",
    "\n",
    "### Uniones (Joins)\n",
    "Usando la librería pandas se pueden realizar 4 tipos de uniones para cruzar información entre dos fuentes de datos, ver Figura abajo. \n",
    "* INNER JOIN: este tipo de cruce incluye solo los resgistros que coincieden en las dos tablas\n",
    "* LEFT JOIN:  en este tipo de cruce se incluyen todos los registros de la primera tabla aunque no aparezcan coincidencias en la segunda. Cuando no hay coincidencias en la segunda tabla los campos correspondientes a esta aparecerán como nulos.\n",
    "* RIGHT JOIN: en este tipo de cruce se incluyen todos los registros de la segunda tabla aunque no aparezcan coincidencias en la primera. Cuando no hay coincidencias en la primer tabla los campos correspondientes a esta aparecerán como nulos.\n",
    "* OUTER JOIN O FULL JOIN: combina todos los registros de ambas tablas aunque no existan coincidencias en la otra tabla. \n",
    "\n",
    "![Los tipos de uniones que se pueden ejecutar en pandas](https://letsdobigdata.files.wordpress.com/2016/03/joins.png)\n",
    "\n",
    "La combinación a usar depende del análisis que se requiera con los datos. Lo más común es realizar un cruce de tipo Inner Join, debido a que muestra los registros cuando aparecen relacionados en ambas tablas. Sin embargo, en \n",
    "ocasiones se quiere saber que pasa con todos los registros de la primera tabla aunque no se tengan coincidencias. Alternativamente, quizá, lo menos usual es hacer combinaciones de tipo RIGHT o OUTER. Generalmente, estas son usadas cuando se quiere saber por qué no se tienen coincidencias, o cuáles registros no cumplen con la relación especificada.\n",
    "\n",
    "Ya que desconocemos cuales son los registros perdidos en los 2 dataframes que hemos construido y es necesario para continuar nuestro preprocesamiento el unir la información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3=df.merge(agr_df,left_index=True,right_index=True,how=\"inner\")\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2  \n",
    "¿Cuáles son los 3 registros que no se incluyen en df3 ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.isin(df3.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sin_registros=df.index.isin(df3.index)\n",
    "df.iloc[~sin_registros,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si deseamos realizar una filtración sobre algún valor relevante por ejemplo el área podremos revertir el proceso usando el operador `==`  que retorna `True` en el caso que dos objetos tengan el mismo valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_england=df3[df3[\"area\"]==\"NEW ENGLAND AREA\"]\n",
    "new_england\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El comando   `df3[\"area\"]==\"NEW ENGLAND AREA\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[\"area\"]==\"NEW ENGLAND AREA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "devuelve una serie boleana  con el mismo número de filas de la base`df3`, donde cada valor es `True` o `False` dependiendo si el valor de `area` de un registro  toma el valor de \"NEW ENGLAND AREA\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrupación por área geográfica\n",
    "\n",
    "En el Analisis de la información se suelen usar funciones de resumen, las cuales plantean el agrupamiento de ciertas características por categorías. Para más información consultar [gropby().](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html).\n",
    "\n",
    "Para nuestro desarrollo es de interés el revisar si el comportamiento de las variables se mantiene en cada una de las áreas geográficas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.groupby(\"area\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí, el objeto DataFrameGroupBy  contiene un objeto DataFrame para cada grupo (en este caso, un objeto DataFrame para cada símbolo). Específicamente, cada elemento del objeto es una tupla que contiene el identificador de grupo (en este caso el símbolo), y las filas correspondientes del DataFrame que tienen ese símbolo).\n",
    "\n",
    "La librería `pandas`  permite iterar sobre el objeto groupby() para ver lo que hay dentro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df = df3.groupby([\"area\"]) # Datos del grupo en df3 filtrados por el área\n",
    "# Haciendo un bucle a través de los grupos\n",
    "for item in group_df:\n",
    "    print(type(item)) # Mostrando el tipo de artículo en df3\n",
    "    print(item[0]) # área\n",
    "    print(item[1].head()) # DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando el método  `groupby()` con el método `describe()` y apliquémoslo a cada símbolo para\n",
    "analizar la distribución de las características la variable ----."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df = df3.groupby([\"area\"]) # Datos del grupo en df3 filtrados por el área\n",
    "# Bucle a través de los grupos\n",
    "for item in group_df:\n",
    "    print(\"------Área: \", item[0])\n",
    "    group_df1 = item[1]\n",
    "    df_relevante = group_df[[\"totrev\"]]\n",
    "    print(df_relevante.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En `pandas`tenemos una manera más sencilla de mostrar estos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[[\"area\",\"totrev\"]].groupby(\"area\").describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos resultados son iguales a los realizados con el ciclo `for`. Los objetos de tipo `DataFrameGroupBy` permiten una rápida salida de generación de estadísticas para grupos de interés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3\n",
    "\n",
    "Realice una agrupación por la variable creditcd_x y encuentre el valor de la desviación estándar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.groupby(\"creditcd_x\").mean()\n",
    "# realice el ejercicio en este espacio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etiquetando valores de total de ingresos en categorías\n",
    "\n",
    "Revisamos el comportamiento de `totrev` y encontramos una gran variabilidad, en ocasiones la agrupación de variables cuantitativas en diferentes categorías nos ayuda a tener una mejor visión del conjunto de datos. \n",
    "\n",
    "Crearemos una nueva variable `Nivel_totrev`  que catalogue a la variable total de ingresos `totrev` en 2 posibles niveles, alto en el caso que `totrev`  sea mayor al cuantil 50 y baja en otro caso. cada valor de percentil debe ser calculado por cada `area` para asegurar que el +area geografíca sea evaluada adicionalmente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pencentiles50 = df3.groupby(\"area\")[\"totrev\"].quantile(0.5) # percentil 50\n",
    "print(pencentiles50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como nos gustaría etiquetar los ingreos en alto y bajopara  cada área geográfica, haremos uso del método\n",
    "`np.where()` en la biblioteca numpy. Este método toma una entrada y comprueba una condición lógica: si la\n",
    "condición es verdadera, devolverá su segundo argumento, mientras que si la condición es falsa, devolverá su\n",
    "tercer argumento. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop a través de los símbolos\n",
    "areas = ['ATLANTIC SOUTH AREA',\n",
    " 'CALIFORNIA NORTH AREA',\n",
    " 'CENTRAL-SOUTH TEXAS AREA',\n",
    " 'CHICAGO AREA',\n",
    " 'DALLAS AREA',\n",
    " 'DC-MARYLAND-VIRGINIA AREA',\n",
    " 'GREAT LAKES AREA',\n",
    " 'HOUSTON AREA',\n",
    " 'LOS ANGELES AREA',\n",
    " 'MIDWEST AREA',\n",
    " 'NEW ENGLAND AREA',\n",
    " 'NEW YORK CITY AREA',\n",
    " 'NORTH FLORIDA AREA',\n",
    " 'NORTHWEST-ROCKY MOUNTAIN AREA',\n",
    " 'OHIO AREA',\n",
    " 'PHILADELPHIA AREA',\n",
    " 'SOUTH FLORIDA AREA',\n",
    " 'SOUTHWEST AREA',\n",
    " 'TENNESSEE AREA'] # registro de las áreas\n",
    "lista_df = []\n",
    "# ciclo sobre todos los símbolos\n",
    "for i in areas:\n",
    "    print(\"Etiqueta por área: \" + i)\n",
    "    temp_df = df3[df3[\"area\"] == i] .copy()\n",
    "    umbral_punto = pencentiles50.loc[i]\n",
    "    temp_df[\"Nivel_totrev\"] = np.where(temp_df[\"totrev\"] < umbral_punto, \"Bajo\", \"Alto\") \n",
    "    lista_df.append(temp_df)\n",
    "df_con_etiquetas = pd.concat(lista_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con_etiquetas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_con_etiquetas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos hacer una evaluaciónd de como es el comportamiento de los minutos gastados y el nivel de ingresos de los clientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Existe relación alguna entre el total de minutos usados con la compañía y el ingreso total de los clientes?\n",
    "\n",
    "Para explorar la relación entre el nivel de total de ingresos y el número promedio de llamadas, agrupemos por\n",
    "Nivel_totrev y miremos ingreso total promedio por cada +area geográfica.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_con_etiquetas.groupby(['area','Nivel_totrev'])[['totmou']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 4\n",
    "\n",
    "\n",
    "Escriba el código para categorizar  el total de ingresos  baja, media y alta volatilidad, donde:\n",
    "\n",
    "`\n",
    "si totrev > (percentil 75 de totrev para el área dada):\n",
    "Nivel_totrev = 'Alto'\n",
    "o si VolStat > (percentil 25 de totrev para el área dada):\n",
    "Nivel_totrev  = 'Medio'\n",
    "de lo contrario:\n",
    "Nivel_totrev  = 'Bajo'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pencentiles25 = df3.groupby(\"area\")[\"totrev\"].quantile(0.25) # percentil 50\n",
    "pencentiles75 = df3.groupby(\"area\")[\"totrev\"].quantile(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = ['ATLANTIC SOUTH AREA',\n",
    " 'CALIFORNIA NORTH AREA',\n",
    " 'CENTRAL-SOUTH TEXAS AREA',\n",
    " 'CHICAGO AREA',\n",
    " 'DALLAS AREA',\n",
    " 'DC-MARYLAND-VIRGINIA AREA',\n",
    " 'GREAT LAKES AREA',\n",
    " 'HOUSTON AREA',\n",
    " 'LOS ANGELES AREA',\n",
    " 'MIDWEST AREA',\n",
    " 'NEW ENGLAND AREA',\n",
    " 'NEW YORK CITY AREA',\n",
    " 'NORTH FLORIDA AREA',\n",
    " 'NORTHWEST-ROCKY MOUNTAIN AREA',\n",
    " 'OHIO AREA',\n",
    " 'PHILADELPHIA AREA',\n",
    " 'SOUTH FLORIDA AREA',\n",
    " 'SOUTHWEST AREA',\n",
    " 'TENNESSEE AREA'] # registro de las áreas\n",
    "lista_df = []\n",
    "# ciclo sobre todos los símbolos\n",
    "for i in areas:\n",
    "    print(\"Etiqueta por área: \" + i)\n",
    "    temp_df = df3[df3[\"area\"] == i] .copy()\n",
    "    umbral_punto1 = pencentiles25.loc[i]\n",
    "    umbral_punto2 = pencentiles75.loc[i]\n",
    "    lv=[]\n",
    "    for i in temp_df['totrev']:\n",
    "        if i<umbral_punto1:\n",
    "            lv.append('Bajo')\n",
    "        elif i<umbral_punto2:\n",
    "            lv.append('Medio')\n",
    "        else:\n",
    "            lv.append('Alto')\n",
    "    temp_df['Nivel']=lv\n",
    "    lista_df.append(temp_df)\n",
    "df_con_etiquetas = pd.concat(lista_df)\n",
    "# realice el ejercicio en este espacio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con_etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con_etiquetas.groupby(['area','Nivel'])[['totmou']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de total de llamadas y total de ingresos\n",
    "\n",
    "Ya hemos respondido satisfactoriamente a nuestra pregunta original. Sin embargo, no es necesario solamente\n",
    "analizar los datos en formato tabular. Python contiene una funcionalidad que le permite analizar sus datos\n",
    "visualmente también.\n",
    "\n",
    "Usaremos la funcionalidad de pandas sobre la librería estándar de graficación de Python, `matplotlib`. Vamos\n",
    "a importar la librería e instruir a Jupyter que muestre los gráficos en línea (es decir, mostrar los gráficos en\n",
    "la pantalla del cuaderno para que podamos verlos mientras ejecutamos el código):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modules = dir()\n",
    "print(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Graficar en el cuaderno\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.hist(df3[\"totrev\"],bins=13,color=\"#237AAF\")\n",
    "plt.title('Histograma de variable totrev')\n",
    "plt.xlabel(\"totrev\");plt.ylabel(\"Frecuencia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plt.style.available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.boxplot(df3[\"totrev\"])\n",
    "plt.title('Boxplot de variable totrev')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gráficas a partir de `groupby`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df4=df_con_etiquetas.groupby(['area','Nivel_totrev'])[['totmou']].mean()\n",
    "df4.plot(kind='barh',figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gráficas de `pandas`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modulo`.plot()` genera por defecto una gráfica de línea, existen varios gráficos para los `DataFrameGroup`\n",
    "\n",
    "    - 'line' : Gráfica de línea\n",
    "    - 'bar' :  Diagrama de barras vertical\n",
    "    - 'barh' : Diagrama de barras horizontal\n",
    "    - 'hist' : histograma\n",
    "    - 'box' : boxplot\n",
    "    - 'kde' : Kernel de densidad\n",
    "    - 'area' : Gráfica de área\n",
    "    - 'pie' : Diagrama de torta\n",
    "    - 'scatter' : Diagrama de dispersión\n",
    "    - 'hexbin' : Diagrama de hexágonos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3[\"creditcd_x\"].value_counts().plot(kind=\"pie\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisando la relación entre las dos variables `totrev` y `totmou`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.plot(kind=\"scatter\",x='totrev',y='totmou',c='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Seaborn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(df3[\"totrev\"],orient='v')\n",
    "plt.title('Boxplot de variable totrev')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficas de parcela "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(116,4))\n",
    "sns.pairplot(data=df3, hue='creditcd_x', vars=['totrev','totmou','eqpdays'])\n",
    "plt.title(\"Parcelas\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(x='Nivel_totrev',y='totmou',data=df_con_etiquetas)\n",
    "plt.title('Boxplot múltiple para Nivel de ingresos totales y \\n total de minutos gastados')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.catplot(y=\"totmou\", x=\"Nivel_totrev\", kind=\"box\",    data=df_con_etiquetas, height=4, aspect=4, palette='Set2')\n",
    "sns.catplot(y=\"totmou\", x=\"Nivel_totrev\", kind=\"violin\", data=df_con_etiquetas, height=4, aspect=4, palette='Set2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.catplot(y=\"totmou\", x=\"Nivel_totrev\", hue='creditcd_x', kind='point',data=df_con_etiquetas, aspect=2)\n",
    "ax = sns.catplot(x=\"Nivel_totrev\", kind='count',data=df_con_etiquetas, col='creditcd_x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 5\n",
    "\n",
    "Realice un  boxplot para la variable totmou segmentado por las variable  credict_x y Nivel_totrev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realice el ejercicio en este espacio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen\n",
    "\n",
    "\n",
    "1. Leer datos desde archivos.\n",
    "2. Agregar y manipular datos .\n",
    "3. Analizar estadísticas de resumen y reunir información.\n",
    "4. Usar matplotlib para crear gráficos para hacer análisis visual, además de otras librerías.\n",
    "\n",
    "Para más información\n",
    "\n",
    "> [https://pandas.pydata.org/pandas-docs/stable/getting_started/index.html](https://pandas.pydata.org/pandas-docs/stable/getting_started/index.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
